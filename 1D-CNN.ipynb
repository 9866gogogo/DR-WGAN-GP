{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06380ea2-08b1-4e6e-b175-f017a1707dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np            \n",
    "import pandas as pd               \n",
    "from torch import nn      \n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from EnvironmentXY import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb66c4c9-5453-4043-ba36-e9397b48c5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd33e3e-6757-42fb-89ea-759553933404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    \"\"\"\n",
    "    Function to seed all the possible sources of randomness for reproducibility.\n",
    "    \n",
    "    Args:\n",
    "        seed (int): The seed value to use.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def evaluate_CNN_model(model,x_train,y_train,x_test,y_test,model_name=None):\n",
    "\n",
    "    true = y_train\n",
    "    true = true.cpu().numpy().flatten()\n",
    "    pred = model(x_train.unsqueeze(1))\n",
    "    pred = pred.cpu().detach().numpy().flatten() \n",
    "    \n",
    "    plt.figure(figsize=(7,5),dpi=400, constrained_layout=True)\n",
    "    plt.subplot(221)\n",
    "    plt.plot(range(1,len(y_train)+1),true,color = 'r',label='Measured value')\n",
    "    plt.plot(range(1,len(y_train)+1),pred,color = 'b',label='Estimated value')\n",
    "    plt.xlabel(f'Number of samples in the modeling set({x_train.shape[0]})', fontsize=12, fontproperties=sim_sun)\n",
    "    plt.ylabel(r'''SOM content(g/kg$^{-1}$)''', fontsize=12, fontproperties=sim_sun)\n",
    "    plt.legend(loc='upper left',frameon=False)\n",
    "    plt.title(model_name, fontdict={'fontsize': 11,'family': 'Times New Roman'})\n",
    "    \n",
    "    plt.subplot(222)\n",
    "    # 1:1线   \n",
    "    x = np.linspace(0, max(true), 100)\n",
    "    plt.plot(x, x, linestyle='--', color='black',lw=1, label='1:1 line')\n",
    "    # 拟合线\n",
    "    coefficients = np.polyfit(true, pred, 1)\n",
    "    polynomial = np.poly1d(coefficients)\n",
    "    fitted_values = polynomial(true)\n",
    "    plt.plot(true, fitted_values, 'r-', lw=1, label='Fitted line')\n",
    "    plt.scatter(true, pred,c='black',s=20)\n",
    "    # plt.plot(x, x, linestyle='--', color='black',)\n",
    "    plt.xlabel(r'''Measured SOM content(g/kg$^{-1}$)''', fontsize=12, fontproperties=sim_sun)\n",
    "    plt.ylabel(r'''Estimated SOM content(g/kg$^{-1}$)''', fontsize=12, fontproperties=sim_sun)\n",
    "    mse = mean_squared_error(true, pred)\n",
    "    r2 = r2_score(true, pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    rpd = np.std(true)/rmse\n",
    "    plt.text(30, 0.05, f'R$^2$={r2:.2f}\\nRPD={rpd:.2f}\\nRMSE={rmse:.2f}', fontsize=12, color='black', fontdict={'fontsize': 18,'style': 'italic','family': 'Times New Roman'})\n",
    "    plt.title(model_name, fontdict={'fontsize': 11,'family': 'Times New Roman'})\n",
    "    plt.legend(ncol=1, frameon=False, loc='upper left')\n",
    "\n",
    "    true = y_test\n",
    "    true = true.cpu().numpy().flatten()\n",
    "    pred = model(x_test.unsqueeze(1))\n",
    "    pred = pred.cpu().detach().numpy().flatten() \n",
    "    \n",
    "    plt.subplot(223)\n",
    "    plt.plot(range(1,len(y_test)+1),true,color = 'r',label='Measured value')\n",
    "    plt.plot(range(1,len(y_test)+1),pred,color = 'b',label='Estimated value')\n",
    "    plt.xlabel(f'Number of samples in the testing set({x_test.shape[0]})', fontsize=12, fontproperties=sim_sun)\n",
    "    plt.ylabel(r'''SOM content(g/kg$^{-1}$)''', fontsize=12, fontproperties=sim_sun)\n",
    "    plt.legend(loc='lower left',frameon=False)\n",
    "    plt.title(model_name, fontdict={'fontsize': 11,'family': 'Times New Roman'})\n",
    "    \n",
    "    plt.subplot(224)\n",
    "    # # 1:1线\n",
    "    x = np.linspace(0, max(true), 100)\n",
    "    plt.plot(x, x, linestyle='--', color='black',lw=1, label='1:1 line')\n",
    "    # 拟合线\n",
    "    coefficients = np.polyfit(true, pred, 1)\n",
    "    polynomial = np.poly1d(coefficients)\n",
    "    fitted_values = polynomial(true)\n",
    "    plt.plot(true, fitted_values, 'r-', lw=1, label='Fitted line')\n",
    "    plt.scatter(true, pred,c='black',s=20)\n",
    "    plt.xlabel(r'''Measured SOM content(g/kg$^{-1}$)''', fontsize=12, fontproperties=sim_sun)\n",
    "    plt.ylabel(r'''Estimated SOM content(g/kg$^{-1}$)''', fontsize=12, fontproperties=sim_sun)\n",
    "    # plt.title(title)\n",
    "    mse = mean_squared_error(true, pred)\n",
    "    r2 = r2_score(true, pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    rpd = np.std(true)/rmse\n",
    "    plt.text(24, 0.05, f'R$^2$={r2:.2f}\\nRPD={rpd:.2f}\\nRMSE={rmse:.2f}', fontsize=12, color='black', fontdict={'fontsize': 18,'style': 'italic','family': 'Times New Roman'})\n",
    "    plt.title(model_name, fontdict={'fontsize': 11,'family': 'Times New Roman'})\n",
    "    plt.legend(ncol=1, frameon=False, loc='upper left')\n",
    "    \n",
    "    plt.savefig(f'../../Images/E2/{model_name}.png',bbox_inches = 'tight')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ba1dcf-1576-46a0-891b-295b27dd2a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../Datas/Paper_data/土壤有机质数据/2024第二批数据(96个土样)/re_vis-NIR.csv\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf6b1e4-ad9a-494b-ac33-59da49c25415",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[:,\"X400\":\"X2400\"].values.astype(\"float32\")\n",
    "Y = data[\"SOM\"].values.astype(\"float32\")\n",
    "wavelengths = np.linspace(400, 2400, X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777adeba-31d1-425b-8ebe-01c344e1ff87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = ks.train_test_split(X, Y, test_size = 0.3)\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42 )\n",
    "# draw_boxplot(Y,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ce3a3f-d7a0-42bd-a412-e8028130ba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf448d79-4ae1-4736-b71a-b898937272ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    dataset = torch.utils.data.TensorDataset(*data_arrays)\n",
    "    return DataLoader(dataset, batch_size, shuffle=is_train)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817f0680-f78d-4684-b84b-00180ed7c8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成样本\n",
    "fake_date = pd.read_csv(\"../../Datas/Fake_Datas/E2/7v3/awgan_20250131(33)/[G_epoch=16500]/generate_data[n=564].csv\")\n",
    "\n",
    "fake_x = fake_date.loc[:,\"X400\":\"X2400\"].values.astype(\"float32\")\n",
    "fake_y = fake_date[\"SOM\"].values.astype(\"float32\")\n",
    "\n",
    "# 扩充建模集\n",
    "expend_x = np.vstack((x_train,fake_x))\n",
    "expend_y = np.hstack((y_train,fake_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8bb2b7-d9af-4adf-98e7-1fdcd2545b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gam = 1.2\n",
    "\n",
    "# X_train = glfdiff(MSC(SG(expend_x, w=17, p=2)), gam)\n",
    "# X_test = glfdiff(MSC(SG(x_test, w=17, p=2)), gam)\n",
    "# model_name = f'FOD[{gam}]'\n",
    "\n",
    "# model_name = f'D1'\n",
    "# X_train = D1(MSC(SG(expend_x, w=17, p=2)))\n",
    "# X_test = D1(MSC(SG(x_test, w=17, p=2)))\n",
    "\n",
    "X_train = MSC(SG(expend_x, w=17, p=2))\n",
    "X_test = MSC(SG(x_test, w=17, p=2))\n",
    "model_name = 'R'\n",
    "\n",
    "\n",
    "# gam = 1.6\n",
    "# model_name = f'FOD[{gam}]'\n",
    "# X_train = glfdiff(MSC(SG(x_train, w=17, p=2)), gam)\n",
    "# X_test = glfdiff(MSC(SG(x_test, w=17, p=2)), gam)\n",
    "\n",
    "# model_name = f'D2'\n",
    "# X_train = D2(MSC(SG(x_train, w=17, p=2)))\n",
    "# X_test = D2(MSC(SG(x_test, w=17, p=2)))\n",
    "\n",
    "# model_name = f'R'\n",
    "# X_train = MSC(SG(x_train, w=17, p=2))\n",
    "# X_test = MSC(SG(x_test, w=17, p=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df329b59-4f45-4c6c-95f8-692b23b9d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "X_train = std.fit_transform(X_train)\n",
    "X_test = std.fit_transform(X_test)\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632bc536-987c-40b2-94af-8e642de59978",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(\"cuda\")\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).to(\"cuda\")\n",
    "Y_train = torch.tensor(expend_y, dtype=torch.float32).to(\"cuda\")\n",
    "Y_test = torch.tensor(y_test, dtype=torch.float32).to(\"cuda\")\n",
    "\n",
    "a=X_train.shape[0] \n",
    "b = X_test.shape[0]\n",
    "\n",
    "Y_train = Y_train.reshape(a, 1)\n",
    "Y_test  = Y_test.reshape(b, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a105cb-33e9-44ba-bdce-fa597515461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = args\n",
    "    def forward(self, x):\n",
    "        return x.view((x.size(0),)+self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8244ad-8c35-439a-b3c2-443d42b803f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def clear_vars_on_exit():\n",
    "    before_globals = set(globals().keys())\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        after_globals = set(globals().keys())\n",
    "        new_globals = after_globals - before_globals\n",
    "        for var in new_globals:\n",
    "            if var in globals():\n",
    "                del globals()[var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4394e025-5c1f-480b-8d85-d43689ca4362",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 调用函数设置种子\n",
    "# seed_value = 42  # 选择一个固定的种子值\n",
    "seed_value = 42  # 选择一个固定的种子值\n",
    "seed_everything(seed_value)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "class HuberLoss(nn.Module):\n",
    "    def __init__(self, delta=1.0):\n",
    "        super(HuberLoss, self).__init__()\n",
    "        self.delta = delta\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        error = y_pred - y_true\n",
    "        abs_error = torch.abs(error)\n",
    "        quadratic = 0.5 * (abs_error ** 2)\n",
    "        linear = self.delta * (abs_error - 0.5 * self.delta)\n",
    "        loss = torch.where(abs_error <= self.delta, quadratic, linear)\n",
    "        return torch.mean(loss)\n",
    "\n",
    "if model_name=='D2':\n",
    "    layer_number = 384\n",
    "else:\n",
    "    layer_number = 400\n",
    "\n",
    "net = None\n",
    "\n",
    "net = nn.Sequential( \n",
    "    nn.Conv1d(1, 16, 9,padding='same', stride=1),\n",
    "    nn.BatchNorm1d(16),\n",
    "    # nn.LeakyReLU(0.01),\n",
    "    nn.SELU(),\n",
    "    \n",
    "    nn.MaxPool1d(kernel_size = 2, stride=2),\n",
    "    \n",
    "    nn.Conv1d(16, 32, 9,padding='same', stride=1),\n",
    "    nn.BatchNorm1d(32),\n",
    "    # nn.LeakyReLU(0.01),\n",
    "    nn.SELU(),\n",
    "    \n",
    "    nn.MaxPool1d(kernel_size = 2, stride=2),\n",
    "    \n",
    "    nn.Conv1d(32, 16, 9,padding='same', stride=1),\n",
    "    nn.BatchNorm1d(16),\n",
    "    # nn.LeakyReLU(0.01),\n",
    "    nn.SELU(),\n",
    "    \n",
    "    nn.MaxPool1d(kernel_size = 2, stride=2),\n",
    "\n",
    "    nn.Flatten(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(layer_number,128),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(128,1),\n",
    "    # nn.Dropout(0.5),\n",
    "    # nn.Linear(64,1),\n",
    "    \n",
    "    \n",
    ").to(\"cuda\")\n",
    "\n",
    "with clear_vars_on_exit():\n",
    "    num_epochs = 250\n",
    "    batch_size =32\n",
    "    ee = 0    \n",
    "    \n",
    "    loss = nn.SmoothL1Loss()\n",
    "    # loss = HuberLoss(delta=1.0)\n",
    "    trainer = optim.Adam(net.parameters(), lr=0.0002, weight_decay=1e-4)\n",
    "    \n",
    "    dataset = TensorDataset(X_train, Y_train)\n",
    "    train_size = int(len(dataset) * 0.7)  \n",
    "    val_size = len(dataset) - train_size \n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    # train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "                  \n",
    "    best_loss = float('inf')  \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        for X_, y_ in train_loader:\n",
    "            X_, y_ = X_.unsqueeze(1).to(\"cuda\"), y_.to(\"cuda\")\n",
    "            yy = net(X_)\n",
    "            l = loss(yy, y_)\n",
    "            trainer.zero_grad()\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "        net.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_val, y_val in val_loader:\n",
    "                X_val, y_val = X_val.unsqueeze(1).to(\"cuda\"), y_val.to(\"cuda\")\n",
    "                val_loss += loss(net(X_val), y_val).item()\n",
    "        val_loss /= len(val_loader)\n",
    "    \n",
    "        print(f'Epoch {epoch + 1}, Validation Loss: {val_loss:.6f}, Best Loss: {best_loss:.6f}, Best Model Epoch: {ee + 1}')\n",
    "    \n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            # torch.save(net.state_dict(), f'../../models/E2/1D-CNN/DR-WGAN-GP/{model_name}_best_model.pth')\n",
    "            ee = epoch\n",
    "        if epoch-ee>=10:\n",
    "            torch.save(net.state_dict(), f'../../models/E2/1D-CNN/DR-WGAN-GP/{model_name}_best_model.pth')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b09d050-c633-4ddf-9ede-772d1e379fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(f'../../models/E2/1D-CNN/DR-WGAN-GP/{model_name}_best_model.pth') \n",
    "net.load_state_dict(state_dict)  \n",
    "net.eval()\n",
    "\n",
    "evaluate_CNN_model(net,X_train,Y_train,X_test,Y_test,model_name=f'{model_name}_CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e920d9-a65b-4456-96ca-b58270d4a3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "del net,state_dict\n",
    "gc.collect()  # 手动触发垃圾回收"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "virtual_environment_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
