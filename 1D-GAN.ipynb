{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc8df33-c40b-4c34-a420-edd4153df87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from scipy import signal\n",
    "from scipy.stats import pearsonr\n",
    "# import pywt  # Continuous Wavelet Transform\n",
    "import copy\n",
    "import scipy.stats as st\n",
    "from scipy.special import comb\n",
    "import seaborn as sns\n",
    "from sympy import *\n",
    "import math\n",
    "\n",
    "import kennard_stone as ks \n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c205334-d50d-4695-a879-c3ae907df1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7af4e0-3913-4edd-869f-83abbadce4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../Datas/Paper_data/土壤有机质数据/2024第二批数据(96个土样)/re_vis-NIR.csv'\n",
    "data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381f4b52-8a85-4c85-b48c-fdcaaa742776",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c73400-9d6a-40ac-ac21-eca24fd7c8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[:,\"X400\":\"X2400\"].values.astype(\"float32\")\n",
    "Y = data[\"SOM\"].values.astype(\"float32\")\n",
    "wavelengths = np.linspace(400, 2400, X.shape[1])\n",
    "train_data = data.values.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c845f6-f004-4f9e-9866-b94582a00f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_hyperspectral_image(_data, title=None, x_label_start=0, sample_interval=10):\n",
    "    y = _data\n",
    "    x = range(0, _data.shape[1])\n",
    "    axis_x_label = range(x_label_start, y.shape[1] * sample_interval + x_label_start, sample_interval)\n",
    "    fig, ax = plt.subplots(figsize=[6, 4],dpi=400)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    for i in range(0, y.shape[0]):\n",
    "        plt.plot(x, y[i])\n",
    "    xticks_interval = 20 \n",
    "    # xticks_interval = 200 \n",
    "    plt.xticks(x[::xticks_interval], axis_x_label[::xticks_interval], rotation=0)\n",
    "    plt.xlabel('Wavelength/nm', fontsize=13)\n",
    "    plt.ylabel('Reflectance', fontsize=13)\n",
    "    plt.title(title, fontsize=15)\n",
    "    # plt.grid(linestyle = '--',alpha=0.7)\n",
    "    # plt.savefig(\"C:/Users/xy445/Desktop/Reflectance.png\")\n",
    "    plt.show()\n",
    "\n",
    "def SG(data, w=11, p=2):\n",
    "    return signal.savgol_filter(data, w, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ba71bd-d918-45a9-a284-b25719546f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_hyperspectral_image(SG(X,w=17,p=2),'Raw',400,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e112cdb4-8f93-4bf2-bfa1-c053309a5739",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = ks.train_test_split(train_data[:,1:], train_data[:,:1], test_size=0.3)\n",
    "\n",
    "gan_train_data = np.hstack((y_train,x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4041dcb7-a41b-4220-be87-54546222a787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "normalized_data = scaler.fit_transform(gan_train_data)\n",
    "\n",
    "# reconstructed_data = scaler.inverse_transform(normalized_data)\n",
    "\n",
    "gan_data_matrix = np.zeros((len(normalized_data),217,1)).astype(np.float32)\n",
    "for i in range(len(normalized_data)):\n",
    "    gan_data_matrix[i] = normalized_data[i].reshape((217,1))\n",
    "gan_data_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293434fa-f93c-4d29-bab7-c193a9fa0552",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100      # 噪声向量维度\n",
    "signal_length = 217   # 信号长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee558e96-b817-4621-be0a-9a0ab37446fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Input(shape=(latent_dim,)),\n",
    "        layers.Dense(32, activation='relu', kernel_initializer='he_normal'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(64, activation='relu', kernel_initializer='he_normal'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(signal_length, activation='tanh')\n",
    "    ])\n",
    "    return model\n",
    "g_model = build_generator()\n",
    "g_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74099d1-890a-4104-90c4-dfc5fb90f236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Input(shape=(signal_length, 1)),\n",
    "        layers.Conv1D(32, 5, strides=2, padding='same'),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        layers.Conv1D(64, 5, strides=2, padding='same'),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "d_model = build_discriminator()\n",
    "d_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a8fab1-8334-45be-b0fb-62491a14c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardGAN(keras.Model):\n",
    "    def __init__(self, generator, discriminator, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        # self.g_optimizer = tf.keras.optimizers.Adam(0.0002, beta_1=0.5)\n",
    "        # self.d_optimizer = tf.keras.optimizers.Adam(0.0002, beta_1=0.5)\n",
    "        self.g_optimizer = tf.keras.optimizers.Adam(learning_rate=tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.0002, decay_steps=10000, decay_rate=0.9, staircase=True), beta_1=0.5, beta_2=0.999)\n",
    "        self.d_optimizer = tf.keras.optimizers.Adam(learning_rate=tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.0002, decay_steps=10000, decay_rate=0.9, staircase=True), beta_1=0.5, beta_2=0.999)\n",
    "        self.loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "        \n",
    "        self.g_loss_metric = tf.keras.metrics.Mean(name=\"g_loss\")\n",
    "        self.d_loss_metric = tf.keras.metrics.Mean(name=\"d_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.g_loss_metric, self.d_loss_metric]\n",
    "\n",
    "    def train_step(self, real_data):\n",
    "        batch_size = tf.shape(real_data)[0]\n",
    "        \n",
    "        noise = tf.random.normal(shape=(batch_size, latent_dim))   \n",
    "\n",
    "        valid = tf.ones((batch_size, 1)) * 0.9  # 真实标签设为0.9\n",
    "        fake = tf.zeros((batch_size, 1)) * 0.1  # 假标签设为0.1\n",
    "\n",
    "        # valid = tf.ones((batch_size, 1))\n",
    "        # fake = tf.zeros((batch_size, 1))\n",
    "\n",
    "        with tf.GradientTape() as d_tape:\n",
    "            generated_data = self.generator(noise)\n",
    "            generated_data = tf.reshape(generated_data, [-1, signal_length, 1])\n",
    "            \n",
    "            real_pred = self.discriminator(real_data)\n",
    "            fake_pred = self.discriminator(generated_data)\n",
    "            \n",
    "            d_real_loss = self.loss_fn(valid, real_pred)\n",
    "            d_fake_loss = self.loss_fn(fake, fake_pred)\n",
    "            d_total_loss = (d_real_loss + d_fake_loss) / 2\n",
    "\n",
    "        d_gradients = d_tape.gradient(d_total_loss, self.discriminator.trainable_variables)\n",
    "        self.d_optimizer.apply_gradients(zip(d_gradients, self.discriminator.trainable_variables))\n",
    "\n",
    "        with tf.GradientTape() as g_tape:\n",
    "            regenerated_data = self.generator(noise)\n",
    "            regenerated_data = tf.reshape(regenerated_data, [-1, signal_length, 1])\n",
    "            \n",
    "            valid_pred = self.discriminator(regenerated_data)\n",
    "            \n",
    "            g_loss = self.loss_fn(valid, valid_pred)\n",
    "\n",
    "        g_gradients = g_tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        self.g_optimizer.apply_gradients(zip(g_gradients, self.generator.trainable_variables))\n",
    "\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        self.d_loss_metric.update_state(d_total_loss)\n",
    "        \n",
    "        return {\n",
    "            \"generator_loss\": self.g_loss_metric.result(),\n",
    "            \"discriminator_loss\": self.d_loss_metric.result()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb297999-1d85-4407-83a4-58603adac7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=65, latent_dim=128, last_end_epochs=0):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "        self.last_end_epochs = last_end_epochs\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "      if (self.last_end_epochs+epoch+1) % 100 == 0:\n",
    "        self.model.discriminator.save(f'../../models/1D-GAN[20250131]/GAN-D[{self.last_end_epochs+epoch+1}].h5')\n",
    "        self.model.generator.save(f'../../models/1D-GAN[20250131]/GAN-G[{self.last_end_epochs+epoch+1}].h5')\n",
    "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "        generated_data = self.model.generator(random_latent_vectors, training=False)\n",
    "        generated_data = generated_data.numpy()\n",
    "        gan_data_matrix = np.zeros((len(generated_data),217)).astype(np.float32)\n",
    "        for i in range(len(gan_data_matrix)):\n",
    "            gan_data_matrix[i] = generated_data[i].reshape((217))\n",
    "            gan_data_matrix[i] = scaler.inverse_transform(gan_data_matrix[i].reshape(1, -1))\n",
    "        reflact = gan_data_matrix[:,1:]\n",
    "        # fig, ax = plt.subplots(figsize=[6, 4],dpi=400)\n",
    "        x = range(350, reflact.shape[1]+350)\n",
    "        for i in range(0, reflact.shape[0]):\n",
    "          plt.plot(x, reflact[i])\n",
    "        plt.grid(linestyle = '--',alpha=0.7)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ebb5ca-55ab-4348-81ff-6e9d887f60a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    epochs = 20000\n",
    "    last_end_epochs = 0 \n",
    "    cbk = GANMonitor(num_img=65, latent_dim=latent_dim, last_end_epochs=last_end_epochs)\n",
    "\n",
    "    generator = build_generator()\n",
    "    discriminator = build_discriminator()\n",
    "    if last_end_epochs != 0:\n",
    "        generator = tf.keras.models.load_model(f'../../models/1D-GAN[20250131]/GAN-G[{last_end_epochs}].h5')\n",
    "        discriminator = tf.keras.models.load_model(f'../../models/1D-GAN[20250131]/GAN-D[{last_end_epochs}].h5')\n",
    "    \n",
    "    standard_gan = StandardGAN(generator=generator, discriminator=discriminator)\n",
    "    standard_gan.compile()\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(gan_data_matrix)\n",
    "    dataset = dataset.shuffle(buffer_size=10000)\n",
    "    dataset = dataset.batch(65, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    real_signals = dataset\n",
    "    \n",
    "    history = standard_gan.fit(\n",
    "        real_signals,\n",
    "        batch_size=65,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        callbacks=[cbk]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4239df69-873b-43c5-83bb-ab2780a91ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6dccf8-0438-4fe3-8dda-a2efc01dd8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd900e0-44cf-4f11-b728-5654fc839df0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
